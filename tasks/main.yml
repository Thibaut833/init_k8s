---
# tasks file for init_k8s

- name: J'installe le paquet open-iscsi et python3-kubernetes
  ansible.builtin.apt:
    name:
      - open-iscsi
      - python3-kubernetes
    state: present
    update_cache: true

- name: Je configure le cluster sur le controlplane
  delegate_to: "{{ play_hosts | first }}"
  run_once: true
  block:
    - name: Je vérifie si le cluster tourne
      ansible.builtin.uri:
        url: "https://{{ ansible_host }}:6443/healthz"
        method: GET
        validate_certs: false
        status_code: ["200", "-1"]
      register: check_k8s
      ignore_errors: true

    - name: J'initialise le cluster kube sur le controlplane
      ansible.builtin.command:
        cmd: kubeadm init --pod-network-cidr=10.244.0.0/16
      register: init_controlplane
      changed_when: init_controlplane.rc == 0
      when:
        - check_k8s.status != 200
        - check_k8s.json is not defined or check_k8s.json != "ok"

    - name: Je mets l'export kubeconfig dans zshrc du controlplane
      ansible.builtin.lineinfile:
        path: ~/.zshrc
        insertafter: EOF
        line: "export KUBECONFIG=/etc/kubernetes/admin.conf"

    - name: Je crée la commande pour rejoindre le controlplane
      ansible.builtin.set_fact:
        kubeadm_join: "{{ init_controlplane.stdout_lines[-2:] | join('') | regex_replace('\\\\\\t', '') }}"
      when:
        - check_k8s.status != 200
        - check_k8s.json is not defined or check_k8s.json != "ok"

    - name: Je regarde si le fichier encryptionConfig.yaml existe
      ansible.builtin.stat:
        path: "/etc/kubernetes/enc/encryptionConfig.yaml"
      register: exists_encryptionconfig

    - name: Je chiffre la base etcd
      when: not exists_encryptionconfig.stat.exists
      block:
        - name: Je crée la clé de chiffrement pour etcd
          ansible.builtin.shell:
            cmd: "head -c 32 /dev/urandom | base64"
          register: key_chiff          

        - name: Je crée le dossier enc dans /etc/kubernetes/
          ansible.builtin.file:
            path: /etc/kubernetes/enc
            state: directory
            recurse: true
            owner: root
            group: root

        - name: Je copie le template encryptionConfig dans le dossier
          ansible.builtin.template:
            src: "{{ role_path }}/templates/encryptionConfig.j2"
            dest: /etc/kubernetes/enc/encryptionConfig.yaml
            mode: "770"

        - name: Je lis la configuration de kube-apiserver
          ansible.builtin.slurp:
            src: /etc/kubernetes/manifests/kube-apiserver.yaml
          register: conf_kubeapiserv  

        - name: Je mets la conf dans une var
          ansible.builtin.set_fact:
            conf_kubeapiserv_work: "{{ conf_kubeapiserv['content'] | b64decode | from_yaml }}"

        - name: J'ajoute l'arg encryption sur la commande kube-apiserver
          ansible.builtin.set_fact:
            newcommandekubeapi: "{{ conf_kubeapiserv_work.spec.containers[0].command + ['--encryption-provider-config=/etc/kubernetes/enc/encryptionConfig.yaml']}}"

        - name: Je remplace la liste de commande pour kube-apiserver avec la nouvelle
          ansible.builtin.set_fact:
            conf_kubeapiserv_work: "{{ conf_kubeapiserv_work | replace(conf_kubeapiserv_work.spec.containers[0].command, newcommandekubeapi) }}"

        - name: J'ajoute le volumeMount enc
          ansible.builtin.set_fact:
            newvmlist: "{{ conf_kubeapiserv_work.spec.containers[0].volumeMounts + vm_enc }}"
          vars:
            vm_enc:
              - name: enc
                mountPath: /etc/kubernetes/enc
                readOnly: true

        - name: Je remplace la liste de volumeMount par la nouvelle
          ansible.builtin.set_fact:
            conf_kubeapiserv_work: "{{ conf_kubeapiserv_work | replace(conf_kubeapiserv_work.spec.containers[0].volumeMounts, newvmlist) }}"

        - name: J'ajoute le volume enc
          set_fact:
            newvlist: "{{ conf_kubeapiserv_work.spec.volumes + v_enc }}"
          vars:
            v_enc:
              - name: enc
                hostPath:
                  path: /etc/kubernetes/enc
                  type: DirectoryOrCreate

        - name: Je remplace la liste de volumes par la nouvelle
          set_fact:
            conf_kubeapiserv_work: "{{ conf_kubeapiserv_work | replace(conf_kubeapiserv_work.spec.volumes, newvlist) }}"
      
        - name: Je mets à jour mon manifests pod static kube-apiserver
          ansible.builtin.copy:
            content: "{{ conf_kubeapiserv_work | to_yaml  }}"
            dest: /etc/kubernetes/manifests/kube-apiserver.yaml

        - name: Je vérifie la connexion à l'api
          ansible.builtin.wait_for: 
            port: 6443
            delay: 10

    - name: J'installe Flannel
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
      when: deploy_flannel is true

    - name: J'installe Calico
      when: deploy_calico is true
      block:
        - name: J'installe l'operateur Calico
          kubernetes.core.k8s:
            state: present
            kubeconfig: /etc/kubernetes/admin.conf
            src: https://raw.githubusercontent.com/projectcalico/calico/{{ version_calico }}/manifests/calico.yaml

    - name: Je lance la commande pour récupérer le nombre de nodes
      ansible.builtin.shell: kubectl get --kubeconfig=/etc/kubernetes/admin.conf nodes --no-headers | wc -l
      register: num_nodes_raw

    - name: J'extrait le nombre de nodes
      ansible.builtin.set_fact:
        num_nodes: "{{ num_nodes_raw.stdout | int }}" 

- name: debug hostvar check_k8s
  debug:
    var: hostvars[groups['kub'][0]]['check_k8s']

- name: Je fais rejoindre les noeuds sur le cluster kube
  ansible.builtin.command:
    cmd: "{{ hostvars[groups['kub'][0]]['kubeadm_join'] }}"
  register: workers_join_cluster
  changed_when: workers_join_cluster.rc == 0
  delegate_to: "{{ item }}"
  run_once: true
  loop: "{{ play_hosts[1:] }}"
  when:
    - check_k8stoworker.status != 200
    - check_k8stoworker.json is not defined or check_k8stowork.json != "ok"
    - hostvars[groups['kub'][0]]['num_nodes'] <= 1
  vars:
    check_k8stoworker: hostvars[groups['kub'][0]]['check_k8s']

- name: J'installe Metallb
  delegate_to: "{{ play_hosts | first }}"
  run_once: true
  block:
    - name: Je récupère la version de Metallb
      when: version_metallb is not defined
      ansible.builtin.uri:
        url: https://api.github.com/repos/metallb/metallb/releases
      register: releases_metallb
    
    - name: Je déploie Metallb
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: https://raw.githubusercontent.com/metallb/metallb/{% if version_metallb is not defined %}{{ releases_metallb.json[0].tag_name }}{% else %}{{ version_metallb }}{% endif %}/config/manifests/metallb-native.yaml
        wait: true
        wait_timeout: 480
        wait_sleep: 20

    - name: Je génère le fichier de conf metallb
      ansible.builtin.template:
        src: "{{ role_path }}/templates/metallb-ipaddresspool.j2"
        dest: /srv/metallb-pool.yaml
        mode: "660"

    - name: Je crée mon pool d'adresse
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: /srv/metallb-pool.yaml

- name: J'installe OpenEBS
  delegate_to: "{{ play_hosts | first }}"
  run_once: true
  when: deploy_openebs is true
  block:
    - name: J'install open-iscsi
      ansible.builtin.apt:
        name: open-iscsi
        state: present
        update_cache: yes
    
    - name: J'active le service iscsid
      ansible.builtin.systemd_service:
        name: iscsid
        enabled: true
        state: started

    - name: Je lance le déploiement de openebs cstor operator
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: https://openebs.github.io/charts/cstor-operator.yaml
        wait: true
        wait_timeout: 480
        wait_sleep: 20

    - name: J'installe le paquet jq
      ansible.builtin.apt:
        name: jq
        update_cache: true
        state: present

    - name: Je récupère les blocs devices
      ansible.builtin.shell:
        cmd: "kubectl get bd -n openebs --kubeconfig=/etc/kubernetes/admin.conf -o=json | jq -c '.items[] | select(.spec.capacity.storage == {{ oebssizestordisk }}) | {bd: .metadata.name, node: .metadata.labels.nodename}'"
      register: bloc_devices
      when: oebssizestordisk is defined
      failed_when: oebssizestordisk is not defined

    - name: Je mets les bds dans une var nommée bdebs
      ansible.builtin.set_fact:
        bdebs: "{{ bloc_devices.stdout_lines | map('regex_replace', '\\\\', '') | list }}"

    - name: Je copie mon template pour le cstorpoolcluster
      ansible.builtin.template:
        src: "{{ role_path }}/templates/cspc.j2"
        dest: /srv/cspc.yaml
        mode: "660"

    - name: Je lance le déploiement de openebs cstorpoolcluster
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: /srv/cspc.yaml

    - name: Je copie mon template pour le cstor-csi-disk
      ansible.builtin.template:
        src: "{{ role_path }}/templates/cstor-csi-disk.j2"
        dest: /srv/cstor-csi-disk.yaml
        mode: "660"

    - name: Je lance le déploiement de openebs cstorpoolcluster
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: /srv/cstor-csi-disk.yaml

- name: J'installe Longhorn
  delegate_to: "{{ play_hosts | first }}"
  run_once: true
  when: deploy_longhorn is true
  block:
    - name: Je regarde si le module iscsi_tcp est bien chargé
      community.general.modprobe:
        name: "iscsi_tcp"
        state: present

    - name: J'installe le nfsv4 client
      ansible.builtin.apt:
        name: nfs-common
        state: present

    - name: Je copie la conf longhorn sur l'hote
      ansible.builtin.copy:
        src: "{{ role_path }}/files/longhorn.yaml"
        dest: /srv/longhorn-cluster.yaml
        mode: "660"

    - name: Je lance le déploiement de longhorn
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: /srv/longhorn-cluster.yaml

- name: J'installe helm
  delegate_to: "{{ play_hosts | first }}"
  run_once: true
  block:
    - name: J'ajoute la clé du repo helm
      ansible.builtin.get_url:
        url: https://baltocdn.com/helm/signing.asc
        dest: /tmp/helm-signing.asc
        mode: "a+r"
        force: "true"

    - name: Je vérifie la présence de la clé gpg helm dans le folder apt keyrings
      ansible.builtin.stat:
        path: "/etc/apt/keyrings/helm.gpg"
      register: exists_helmasc

    - name: Je de-armor la clé helm
      ansible.builtin.shell: gpg --dearmor < /tmp/helm-signing.asc > /etc/apt/keyrings/helm.gpg
      when: not exists_helmasc.stat.exists

    - name: J'autorise la lecture pour tous sur la clé helm
      ansible.builtin.file:
        path: /etc/apt/keyrings/helm.gpg
        mode: "a+r"

    - name: J'ajoute le repository helm
      ansible.builtin.apt_repository:
        repo: "deb [arch=amd64 signed-by=/etc/apt/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main"

    - name: J'installe le paquet helm
      ansible.builtin.apt:
        name: helm
        state: present
        update_cache: true

- name: J'installe Traefik
  delegate_to: "{{ play_hosts | first }}"
  when: deploy_traefik | bool is true and deploy_nginx | bool is false
  run_once: true
  block:
    - name: Je copie mon fichier de variables pour traefik
      ansible.builtin.copy:
        src: "{{ role_path }}/files/traefikvars.yaml"
        dest: /srv/traefikvars.yaml
        mode: "660"

    - name: J'ajoute le repo helm traefik
      kubernetes.core.helm_repository:
        repo_name: traefik
        repo_url: https://traefik.github.io/charts
        repo_state: present

    - name: J'installe Traefik via helm
      kubernetes.core.helm:
        release_name: prox-traefik
        release_namespace: prox-traefik
        kubeconfig: /etc/kubernetes/admin.conf
        chart_ref: traefik/traefik
        create_namespace: true
        values_files: "/srv/traefikvars.yaml"
        state: present
        chart_version: 23.1.0

- name: J'installe Nginx ingress controller
  delegate_to: "{{ play_hosts | first }}"
  when: deploy_nginx | bool is true and deploy_traefik | bool is false
  run_once: true
  block:
    - name: Je récupère la version de Nginx ingress controller
      ansible.builtin.uri:
        url: https://api.github.com/repos/metallb/metallb/releases
      register: releases_nginxing

    - name: Je récupère le manifest
      ansible.builtin.get_url:
        url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-{{ version_nginxing }}/deploy/static/provider/cloud/deploy.yaml
        dest: /srv/nginx-ingress-deploy.yaml
        mode: "770"

    - name: Je modifie le deployment de l'ingress controller en daemonset
      ansible.builtin.lineinfile:
        path: /srv/nginx-ingress-deploy.yaml
        mode: "770"
        search_string: "kind: Deployment"
        line: "kind: DaemonSet"
        state: present

    - name: Je lance le déploiement de nginx ingress controller
      kubernetes.core.k8s:
        state: present
        kubeconfig: /etc/kubernetes/admin.conf
        src: /srv/nginx-ingress-deploy.yaml
